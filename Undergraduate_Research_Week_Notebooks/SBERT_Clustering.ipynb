{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHcw6tzKRXu8"
      },
      "source": [
        "# SBERT Clustering Directions\n",
        "1.   Select \"Runtime\" at the top menu >> \"Change Runtime Type\" >> \"GPU\"\n",
        "2.   Run the first code cell below by clicking the icon on the left of the cell (a triangle inside a circle). You'll only need to run this once at the beginning of your session.\n",
        "3.   To upload your data, click the \"Files\" icon on the left menu >> \"Upload to session storage\" icon and upload your spreadsheet.\n",
        "4.   Follow the directions below (starting at the second code cell) to run SBERT Clustering.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRdc_s-7CQst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710ff466-a535-4d83-f657-989f357a6c36"
      },
      "source": [
        "# install sentence transformers\n",
        "!pip install -U sentence-transformers\n",
        "\n",
        "# load libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# the pretrained model that SBERT embeddings are computed with\n",
        "embedder = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "# function for SBERT Cluster\n",
        "def SBERTCluster(df, k):\n",
        "\n",
        "  # make sure the column of questions is named 'Question' otherwise change column name in the line below\n",
        "  corpus = list(df.final_reviewed_text)\n",
        "\n",
        "  # Generate sentence embeddings with SBERT\n",
        "  corpus_embeddings = embedder.encode(corpus)\n",
        "\n",
        "  # Perform kmeans clustering\n",
        "  num_clusters = k\n",
        "  clustering_model = KMeans(n_clusters=num_clusters)\n",
        "  clustering_model.fit(corpus_embeddings)\n",
        "  cluster_assignment = clustering_model.labels_ # array of the cluster number assigned for each embedded sentence\n",
        "\n",
        "\n",
        "  # Add all cluster results into a dataframe\n",
        "  clustered_sentences = [[] for i in range(num_clusters)]\n",
        "  for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "  # Instead of using DataFrame.append(), build a list of dictionaries\n",
        "  rows = []\n",
        "  for i, cluster in enumerate(clustered_sentences):\n",
        "    rows.append({\n",
        "      'Cluster': i + 1,\n",
        "      'Sentence_Count': len(cluster),\n",
        "      'Text': cluster\n",
        "    })\n",
        "\n",
        "  cluster_df = pd.DataFrame(rows)\n",
        "\n",
        "  # Save cluster number for each row in the original dataframe (adding 1 to cluster index for consistency)\n",
        "  df['Cluster'] = cluster_assignment + 1\n",
        "\n",
        "  return cluster_df, df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install sentence transformers\n",
        "!pip install -U sentence-transformers\n",
        "\n",
        "# load libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# the pretrained model that SBERT embeddings are computed with\n",
        "embedder = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "\n",
        "def SBERTCluster(df, k):\n",
        "    # Extract the list of sentences from the dataframe.\n",
        "    # Make sure the column of questions is named 'final_reviewed_text'\n",
        "    corpus = list(df.final_reviewed_text)\n",
        "\n",
        "    # Generate SBERT embeddings for the corpus\n",
        "    corpus_embeddings = embedder.encode(corpus)\n",
        "\n",
        "    # Perform k-means clustering\n",
        "    clustering_model = KMeans(n_clusters=k, random_state=42)\n",
        "    clustering_model.fit(corpus_embeddings)\n",
        "    cluster_assignment = clustering_model.labels_  # Cluster labels for each sentence\n",
        "\n",
        "    # Build clusters for each sentence to form a summary dataframe\n",
        "    clustered_sentences = [[] for _ in range(k)]\n",
        "    for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "        clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "\n",
        "    # Create a dataframe summarizing clusters with their count and text group\n",
        "    rows = []\n",
        "    for i, cluster in enumerate(clustered_sentences):\n",
        "        rows.append({\n",
        "            'Cluster': i + 1,\n",
        "            'Sentence_Count': len(cluster),\n",
        "            'Text': cluster\n",
        "        })\n",
        "    cluster_df = pd.DataFrame(rows)\n",
        "\n",
        "    # Save cluster number for each sentence in the original dataframe (adjust cluster index by adding 1)\n",
        "    df['Cluster'] = cluster_assignment + 1\n",
        "\n",
        "    # Compute silhouette scores:\n",
        "    #   - Average silhouette score for all clusters.\n",
        "    #   - Silhouette score for each individual sample.\n",
        "    avg_silhouette = silhouette_score(corpus_embeddings, cluster_assignment)\n",
        "    sample_silhouette_values = silhouette_samples(corpus_embeddings, cluster_assignment)\n",
        "\n",
        "    # Optionally, add the per-sample silhouette scores back to the dataframe\n",
        "    df['Silhouette_Score'] = sample_silhouette_values\n",
        "\n",
        "    print(\"Average silhouette score: {:.3f}\".format(avg_silhouette))\n",
        "\n",
        "    return cluster_df, df, avg_silhouette"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKeKHYqAjwf7",
        "outputId": "8e3b71f4-5261-46cd-83b2-f01260d8d7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.50.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-dwnmShGVGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "443b5660-b11c-4b6a-bec3-2ff5df8f5480"
      },
      "source": [
        "# Load in data (change to the name of your spreadsheet file)\n",
        "# uncomment the line below if it's a csv file\n",
        "# df = pd.read_csv('CHANGE TO NAME OF YOUR SPREADSHEET.csv')\n",
        "# otherwise uncomment the line below if it's an excel file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/Holocaust and Genocide Studies Digital Research Lab/Current Projects/Aditya and Billy (URW)/Final Disambiguated Questions.xlsx')\n",
        "\n",
        "# Run SBERT Clustering on your data\n",
        "# - change \"k\" depending on how many clusters you want\n",
        "# - depending on the size of your spreadsheet and the number of clusters you define, this step may take 1-15ish minutes\n",
        "# - each time the line below is run, new results will be produced\n",
        "results = SBERTCluster(df, k=95)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Average silhouette score: 0.119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwEPNSRHPf8C",
        "outputId": "dcbadf86-6110-4293-a5e2-75e461072a3d"
      },
      "source": [
        "# see the results of SBERT Clustering\n",
        "# change the 0 to 1 if you want to see the cluster numbers for each unique question\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(    Cluster  Sentence_Count                                               Text\n",
              " 0         1              44  [Yes… . Do they write here to… ’Huit et quaran...\n",
              " 1         2              85  [ Mr. Barzilai, can you tell me if you were bo...\n",
              " 2         3             172  [How old were you when the Soviets came to Est...\n",
              " 3         4             148  [Did you have a ration card?, Did the Spaniard...\n",
              " 4         5             899  [Yes?, Well?, Yes. And?, Yes, and?, Yes?, Yes....\n",
              " ..      ...             ...                                                ...\n",
              " 90       91             208  [Were you born in Portugal?,  Now, Jürgen, wil...\n",
              " 91       92             104  [Who was in the forest during the deportations...\n",
              " 92       93             274  [Why is it so 'of course' that the Jewish Comm...\n",
              " 93       94             119  [What do you mean when you said you ate dirt f...\n",
              " 94       95             174  [Did you go over to the side where the women a...\n",
              " \n",
              " [95 rows x 3 columns],\n",
              "        file_part  file_num                                               text  \\\n",
              " 0              4         1  Let me tell you frankly: Do not tell me some g...   \n",
              " 1              6         1  … until today. But to you personally. Where di...   \n",
              " 2              8         1  How old were you then? What grade were you in ...   \n",
              " 3             10         1       What means “first grade”? The highest grade?   \n",
              " 4             12         1                                 … of the “Volks-”?   \n",
              " ...          ...       ...                                                ...   \n",
              " 15776        479       119              Was she Jewish, a Jewish girl friend?   \n",
              " 15777        481       119           And she too was there as an Aryan woman?   \n",
              " 15778        483       119                                     Found courage?   \n",
              " 15779        485       119                                                So?   \n",
              " 15780        493       119                             Who were they, French?   \n",
              " \n",
              "        Was_Disambiguated  context_added  is_flagged            Overwritten  \\\n",
              " 0                  False          False       False                  False   \n",
              " 1                  False          False       False                  False   \n",
              " 2                  False           True        True  needs manual revision   \n",
              " 3                  False           True       False                  False   \n",
              " 4                  False           True       False                  False   \n",
              " ...                  ...            ...         ...                    ...   \n",
              " 15776              False           True       False                  False   \n",
              " 15777               True          False       False                  False   \n",
              " 15778              False           True       False                  False   \n",
              " 15779              False           True       False                  False   \n",
              " 15780               True           True        True                   True   \n",
              " \n",
              "        Was_actually_disambiguated  Was_actually_rewritten  was_reverted  \\\n",
              " 0                           False                   False         False   \n",
              " 1                           False                   False         False   \n",
              " 2                           False                   False         False   \n",
              " 3                           False                    True         False   \n",
              " 4                           False                    True         False   \n",
              " ...                           ...                     ...           ...   \n",
              " 15776                       False                    True         False   \n",
              " 15777                        True                   False         False   \n",
              " 15778                       False                    True         False   \n",
              " 15779                       False                    True         False   \n",
              " 15780                       False                   False         False   \n",
              " \n",
              "        was_revised                                final_reviewed_text  \\\n",
              " 0            False  Let me tell you frankly: Do not tell me some g...   \n",
              " 1            False  … until today. But to you personally. Where di...   \n",
              " 2             True  How old were you when the Soviets came to Esto...   \n",
              " 3            False  What does 'first grade' mean in the context of...   \n",
              " 4            False  What did you learn about the concept of 'Volks...   \n",
              " ...            ...                                                ...   \n",
              " 15776        False  Was your girlfriend, who was deported with you...   \n",
              " 15777        False  And your girlfriend too was there as an Aryan ...   \n",
              " 15778        False  Did you find courage during your imprisonment ...   \n",
              " 15779        False   So, what happened next after you were liberated?   \n",
              " 15780         True  Who were the French soldiers in Stuttgart duri...   \n",
              " \n",
              "        Cluster  Silhouette_Score  \n",
              " 0           90          0.020047  \n",
              " 1           11          0.051353  \n",
              " 2            3         -0.020958  \n",
              " 3           64          0.029271  \n",
              " 4           76          0.087778  \n",
              " ...        ...               ...  \n",
              " 15776       20         -0.021862  \n",
              " 15777       28         -0.017490  \n",
              " 15778       49          0.000845  \n",
              " 15779       77          0.055651  \n",
              " 15780       48          0.010333  \n",
              " \n",
              " [15781 rows x 14 columns],\n",
              " np.float32(0.118687056))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qt9WjeHqSR5n",
        "outputId": "83ebc511-ed1b-4703-a070-76b688f109f5"
      },
      "source": [
        "# Download your cluster spreadsheet\n",
        "# change to the file name you want the spreadsheet to have\n",
        "download_file = 'DATA_Clusters.xlsx'\n",
        "\n",
        "# change the 0 to 1 in the lines below, depending on which spreadsheet you want to download\n",
        "# 0 = spreadsheet where each row is a cluster\n",
        "# 1 = spreadsheet where each row is a question (with its corresponding cluster)\n",
        "results[0].to_excel(download_file)\n",
        "files.download(download_file)\n",
        "\n",
        "# you can download the spreadsheet by hovering over the spreadsheet on the right panel and clicking the three dots"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_24fcd5f3-ae77-4234-ae00-aa10ef182d9b\", \"DATA_Clusters.xlsx\", 325125)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}